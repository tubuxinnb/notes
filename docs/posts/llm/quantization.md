---
date: 2025-12-16
categories:
  - LLM Inference
---
# QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving
从这篇文章出发了解一下模型量化技术：[QServe](https://arxiv.org/pdf/2405.04532)
<!-- more -->